{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blood Cell Detection using EfficientDet-D0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UZcVz6Q9UERW",
        "QTr3DUnyUh6w",
        "1fp5UAJQYVwx",
        "CvVnWFJZbIkr",
        "oGoUtaejfgdd",
        "i9UWoNEbgMhu",
        "NjQNpyCLgUc9",
        "ecQ6lfcPgtL0"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMNg09UTT9YG"
      },
      "source": [
        "# Blood Cell Detection using TFOD 2.0\n",
        "\n",
        "**Dataset**: [Link](https://github.com/Shenggan/BCCD_Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZcVz6Q9UERW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ3dvQH1R6Et"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTr3DUnyUh6w"
      },
      "source": [
        "## Setup TensorFlow Object Detection API\n",
        "\n",
        "1. Clone the TFOD 2.0 Repository\n",
        "2. Protobuf Installation/Compilation\n",
        "3. COCO API installation\n",
        "4. Install the Object Detection API\n",
        "5. Test your Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1YaiZjbV3He"
      },
      "source": [
        "### Clone the TFOD 2.0 Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEA38vAtUkWm"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrBi_tJ-WN-x"
      },
      "source": [
        "### Protobuf Installation/Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIwWYu8YV5yd"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX5o-jH9Wfey"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlXxjjKLW-lD"
      },
      "source": [
        "### COCO API installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RERI7mHIXAAv"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOouZOKzXCR1"
      },
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoYWr5LgXECs"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tfNY__FXFjt"
      },
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNSxXsLmXlyq"
      },
      "source": [
        "### Install the Object Installation API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK1VXgbIXa7D"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlOc9UtbXcQ9"
      },
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmy5VWd_XeB9"
      },
      "source": [
        "!python -m pip -q install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlMaz0d3XoDG"
      },
      "source": [
        "### Test the Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykJKORHnXuEs"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKYutotaYEjV"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path.\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "  \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "  Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "      and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "      this function assumes that the boxes to be plotted are groundtruth\n",
        "      boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "      category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "  \"\"\"\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fp5UAJQYVwx"
      },
      "source": [
        "## TensorFlow 2 Object Detection Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dC7GFMgZR6Q"
      },
      "source": [
        "cd content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjj87qX9Zg90"
      },
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/LkRcX9MEQC?key=6rQloXmCNk\" > roboflow.zip; unzip -q roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klOKxP1SZmSO"
      },
      "source": [
        "### Define directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpUTRgxZZkNQ"
      },
      "source": [
        "test_record_fname = '/content/valid/cells.tfrecord'\n",
        "train_record_fname = '/content/train/cells.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/train/cells_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvVnWFJZbIkr"
      },
      "source": [
        "## Configure Custom TensorFlow Object Detection Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwfPOqNpbLH1"
      },
      "source": [
        "MODELS_CONFIG = {\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d1': {\n",
        "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuXK-Tl0cKau"
      },
      "source": [
        "### Choose the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwah0IikcG4d"
      },
      "source": [
        "chosen_model = 'efficientdet-d0'\n",
        "\n",
        "num_steps = 7500  \n",
        "num_eval_steps = 1000\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsCqc6l7cWg3"
      },
      "source": [
        "### Download the pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY8WyxnrcI7o"
      },
      "source": [
        "mkdir /content/models/research/deploy/\n",
        "cd /content/models/research/deploy/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB6NvR78cixV"
      },
      "source": [
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFQzUUDHcqKO"
      },
      "source": [
        "### Download the base training config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPU0BFDpc0kK"
      },
      "source": [
        "cd /content/models/research/deploy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0oRB1YzcwvC"
      },
      "source": [
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCI5URMYeoWI"
      },
      "source": [
        "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9BdBfzEe71k"
      },
      "source": [
        "cd /content/models/research/deploy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zAEqpZ8fVQh"
      },
      "source": [
        "### Writing the `config` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9J1Apmte-Lj"
      },
      "source": [
        "import re\n",
        "print('Writing custom config file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    #fine-tune checkpoint type\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)   \n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW6EN3K4fFlt"
      },
      "source": [
        "!cat /content/models/research/deploy/pipeline_file.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWh56Uycfdeg"
      },
      "source": [
        "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGoUtaejfgdd"
      },
      "source": [
        "## Train the Custom TF2 Object Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BrZQdZtfeU6"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9UWoNEbgMhu"
      },
      "source": [
        "## Evaluating the TF2 Object Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5hNdzuqgS2e"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --checkpoint_dir={model_dir} \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjQNpyCLgUc9"
      },
      "source": [
        "## Start the Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZl-C25ga_k"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecQ6lfcPgtL0"
      },
      "source": [
        "## Export the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vy8QGT2gwNN"
      },
      "source": [
        "ls '/content/training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UalwYOLhgyJm"
      },
      "source": [
        "#run conversion script\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = '/content/fine_tuned_model'\n",
        "\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/training/'\n",
        "print(last_model_path)\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYVG1_F0g2Li"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}